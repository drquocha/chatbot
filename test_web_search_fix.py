#!/usr/bin/env python3

"""
Test script to verify web search context preservation and LLM-based decision making fixes
"""

from chatbot import SimpleChatbot
import time
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def test_context_preservation():
    """Test that conversation context is preserved during web searches"""
    print("ğŸ§ª TEST 1: Context Preservation During Web Search")
    print("=" * 60)

    chatbot = SimpleChatbot()

    # Step 1: Establish context
    print("ğŸ‘¤ User: Xin chÃ o, tÃ´i tÃªn lÃ  Minh")
    response1 = chatbot.get_response("Xin chÃ o, tÃ´i tÃªn lÃ  Minh")
    print(f"ğŸ¤– Bot: {response1}")
    print()

    # Step 2: Ask a non-search question to build more context
    print("ğŸ‘¤ User: TÃ´i Ä‘ang há»c vá» lá»‹ch sá»­ Viá»‡t Nam")
    response2 = chatbot.get_response("TÃ´i Ä‘ang há»c vá» lá»‹ch sá»­ Viá»‡t Nam")
    print(f"ğŸ¤– Bot: {response2}")
    print()

    # Step 3: Ask a question that should trigger web search but reference previous context
    print("ğŸ‘¤ User: Thá»§ tÆ°á»›ng Viá»‡t Nam hiá»‡n táº¡i lÃ  ai?")
    response3 = chatbot.get_response("Thá»§ tÆ°á»›ng Viá»‡t Nam hiá»‡n táº¡i lÃ  ai?")
    print(f"ğŸ¤– Bot: {response3}")
    print()

    # Step 4: CRITICAL TEST - Ask follow-up question that requires context from step 3
    print("ğŸ‘¤ User: Ã”ng áº¥y bao nhiÃªu tuá»•i?")
    response4 = chatbot.get_response("Ã”ng áº¥y bao nhiÃªu tuá»•i?")
    print(f"ğŸ¤– Bot: {response4}")
    print()

    # Step 5: Test if bot still remembers the user's name from step 1
    print("ğŸ‘¤ User: TÃ´i tÃªn gÃ¬?")
    response5 = chatbot.get_response("TÃ´i tÃªn gÃ¬?")
    print(f"ğŸ¤– Bot: {response5}")
    print()

    # Analysis
    print("ğŸ“Š ANALYSIS:")
    context_preserved = "minh" in response5.lower() or "Minh" in response5
    search_context_preserved = "pháº¡m minh chÃ­nh" in response4.lower() or "thá»§ tÆ°á»›ng" in response4.lower()

    print(f"âœ“ Bot remembers user name: {'âœ…' if context_preserved else 'âŒ'}")
    print(f"âœ“ Bot understands 'Ã´ng áº¥y' refers to PM: {'âœ…' if search_context_preserved else 'âŒ'}")
    print()

def test_llm_decision_making():
    """Test the LLM-based web search decision making"""
    print("ğŸ§ª TEST 2: LLM-Based Web Search Decision Making")
    print("=" * 60)

    chatbot = SimpleChatbot()

    test_cases = [
        # Should NOT trigger web search
        ("HÃ£y giáº£i thÃ­ch vá» khÃ¡i niá»‡m 'tin tá»©c' trong ngÃ nh bÃ¡o chÃ­", False),
        ("CÃ¡ch náº¥u phá»Ÿ truyá»n thá»‘ng nhÆ° tháº¿ nÃ o?", False),
        ("Python lÃ  gÃ¬?", False),
        ("Báº¡n cÃ³ thá»ƒ giÃºp tÃ´i há»c tiáº¿ng Anh khÃ´ng?", False),

        # Should trigger web search
        ("Thá»§ tÆ°á»›ng Viá»‡t Nam hiá»‡n táº¡i lÃ  ai?", True),
        ("GiÃ¡ vÃ ng SJC hÃ´m nay bao nhiÃªu?", True),
        ("TÃ¬nh hÃ¬nh COVID-19 má»›i nháº¥t á»Ÿ Viá»‡t Nam", True),
        ("Ai Ä‘ang lÃ  Tá»•ng BÃ­ thÆ° Äáº£ng Cá»™ng sáº£n Viá»‡t Nam?", True),
    ]

    for question, expected_search in test_cases:
        print(f"ğŸ“ Question: {question}")
        actual_search = chatbot.needs_web_search(question)
        result = "âœ…" if actual_search == expected_search else "âŒ"
        print(f"   Expected search: {expected_search} | Actual: {actual_search} {result}")
        print()
        time.sleep(0.5)  # Small delay to avoid rate limiting

def test_conversation_flow():
    """Test complete conversation flow with mixed search and non-search questions"""
    print("ğŸ§ª TEST 3: Mixed Conversation Flow")
    print("=" * 60)

    chatbot = SimpleChatbot()

    questions = [
        "Xin chÃ o, tÃ´i tÃªn lÃ  Nam, tÃ´i Ä‘ang quan tÃ¢m Ä‘áº¿n tÃ¬nh hÃ¬nh chÃ­nh trá»‹",
        "Tá»•ng BÃ­ thÆ° Äáº£ng hiá»‡n táº¡i lÃ  ai?",  # Should search
        "Ã”ng áº¥y tá»« tá»‰nh nÃ o?",  # Should search but maintain context
        "Cáº£m Æ¡n báº¡n. BÃ¢y giá» tÃ´i muá»‘n há»i vá» náº¥u Äƒn",  # Should NOT search
        "CÃ¡ch lÃ m bÃ¡nh mÃ¬ Viá»‡t Nam",  # Should NOT search
        "CÃ²n giÃ¡ bÃ¡nh mÃ¬ hiá»‡n táº¡i á»Ÿ SÃ i GÃ²n bao nhiÃªu?",  # Should search
    ]

    for i, question in enumerate(questions, 1):
        print(f"ğŸ‘¤ Turn {i}: {question}")
        response = chatbot.get_response(question)
        print(f"ğŸ¤– Bot: {response[:100]}{'...' if len(response) > 100 else ''}")
        print()
        time.sleep(1)  # Delay between questions

def main():
    print("ğŸ”§ TESTING WEB SEARCH FIXES")
    print("ğŸ¯ Goals:")
    print("1. Verify conversation context is preserved during web searches")
    print("2. Test LLM-based web search decision making")
    print("3. Ensure natural conversation flow")
    print()

    try:
        test_llm_decision_making()
        print("\n" + "="*80 + "\n")

        test_context_preservation()
        print("\n" + "="*80 + "\n")

        test_conversation_flow()

        print("ğŸ‰ All tests completed!")

    except Exception as e:
        print(f"âŒ Test failed with error: {e}")
        print("Please check your OpenAI API key and internet connection.")

if __name__ == "__main__":
    main()